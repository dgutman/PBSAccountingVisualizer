{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os, sys\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "data_dir = 'data_files/'\n",
    "### Let's first get a list of files from the datafiles directory that I may (or may not?? ) want to parse\n",
    "dataFiles = glob.glob(data_dir+'20160*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_files/20160402\n"
     ]
    }
   ],
   "source": [
    "print dataFiles[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install plotly\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout, Bar\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "executed_jobs = 0\n",
    "LogOutput = []\n",
    "for f in dataFiles:\n",
    "    #print f\n",
    "    LogOutput.append( analyze_data_file( f) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363 days, 6:54:31 1759 days, 16:28:03\n"
     ]
    }
   ],
   "source": [
    "#print len(allExecutedJobs)  ### Only 30,000 jobs apparently were executed.. I must have deleted a lot of them?\n",
    "#pprint( allExecutedJobs[2]) ### Just print the second record\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "totalWallTime = dt.timedelta(hours=0, minutes=0)\n",
    "totalCpuTime =  dt.timedelta(hours=0, minutes=0)\n",
    "\n",
    "for idx,row in enumerate(allExecutedJobs):\n",
    "    ruWt = row['resourcesUsedWallTime']  \n",
    "    #print row\n",
    "\n",
    "    ruWtDt  = dt.datetime.strptime(ruWt,\"%H:%M:%S\")\n",
    "    curJobWallTime = dt.timedelta(hours=ruWtDt.hour, minutes=ruWtDt.minute, seconds=ruWtDt.second)\n",
    "    totalWallTime += curJobWallTime\n",
    "    \n",
    "    ###Lets do the same thing for CPUTime\n",
    "    ruCpu = row['cpuTotal']\n",
    "    ruCpuDt  = dt.datetime.strptime(ruCpu,\"%H:%M:%S\")\n",
    "    curJobCpuTime = dt.timedelta(hours=ruCpuDt.hour, minutes=ruCpuDt.minute, seconds=ruCpuDt.second)\n",
    "    totalCpuTime += curJobCpuTime\n",
    "    #'cpuTotal': '02:27:06'\n",
    "    \n",
    "\n",
    "\n",
    "print totalWallTime,totalCpuTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pprint(LogOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"691f709f-5796-4dae-b1bf-f873a636bc58\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"691f709f-5796-4dae-b1bf-f873a636bc58\", [{\"y\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 71, 182, 653, 276, 264, 89, 277, 233, 9, 0, 2287, 567, 613, 906, 910, 632, 141, 474, 562, 4, 545, 266, 376, 812, 977, 937, 916, 609, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 321, 0, 0, 0, 0, 0, 0, 0], \"x\": [\" /20160313\", \" /20160314\", \" /20160315\", \" /20160316\", \" /20160317\", \" /20160318\", \" /20160319\", \" /20160320\", \" /20160321\", \" /20160322\", \" /20160323\", \" /20160324\", \" /20160325\", \" /20160326\", \" /20160327\", \" /20160328\", \" /20160329\", \" /20160330\", \" /20160331\", \" /20160401\", \" /20160402\", \" /20160403\", \" /20160404\", \" /20160405\", \" /20160406\", \" /20160407\", \" /20160408\", \" /20160409\", \" /20160410\", \" /20160411\", \" /20160412\", \" /20160413\", \" /20160414\", \" /20160415\", \" /20160416\", \" /20160417\", \" /20160418\", \" /20160419\", \" /20160420\", \" /20160421\", \" /20160422\", \" /20160423\", \" /20160424\", \" /20160425\", \" /20160426\", \" /20160427\", \" /20160428\", \" /20160429\", \" /20160430\", \" /20160501\", \" /20160502\", \" /20160503\", \" /20160504\", \" /20160505\", \" /20160506\", \" /20160507\", \" /20160508\", \" /20160509\", \" /20160510\", \" /20160511\", \" /20160512\", \" /20160513\", \" /20160514\", \" /20160515\", \" /20160516\", \" /20160517\", \" /20160518\", \" /20160519\", \" /20160520\", \" /20160521\", \" /20160522\", \" /20160523\", \" /20160524\", \" /20160525\", \" /20160526\", \" /20160527\", \" /20160528\", \" /20160529\", \" /20160530\", \" /20160531\", \" /20160601\", \" /20160602\", \" /20160603\", \" /20160604\", \" /20160605\", \" /20160606\", \" /20160607\", \" /20160608\", \" /20160609\", \" /20160610\", \" /20160611\", \" /20160612\", \" /20160613\", \" /20160614\", \" /20160615\", \" /20160616\", \" /20160617\", \" /20160618\", \" /20160619\", \" /20160620\", \" /20160621\", \" /20160622\", \" /20160623\", \" /20160624\", \" /20160625\", \" /20160626\", \" /20160627\", \" /20160628\", \" /20160629\", \" /20160630\", \" /20160701\", \" /20160702\", \" /20160703\", \" /20160704\", \" /20160705\", \" /20160706\", \" /20160707\", \" /20160708\", \" /20160709\", \" /20160710\", \" /20160711\", \" /20160712\", \" /20160713\", \" /20160714\", \" /20160715\", \" /20160716\", \" /20160717\", \" /20160718\", \" /20160719\", \" /20160720\", \" /20160721\", \" /20160722\", \" /20160723\", \" /20160724\", \" /20160725\", \" /20160726\", \" /20160727\", \" /20160728\", \" /20160729\", \" /20160730\", \" /20160731\", \" /20160801\", \" /20160802\", \" /20160803\", \" /20160804\", \" /20160805\", \" /20160806\", \" /20160807\", \" /20160808\", \" /20160809\", \" /20160810\", \" /20160811\", \" /20160812\", \" /20160813\", \" /20160814\", \" /20160815\", \" /20160816\", \" /20160826\", \" /20160827\", \" /20160829\", \" /20160830\", \" /20160831\", \" /20160901\", \" /20160906\"], \"type\": \"bar\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "xdata = [ x['LogDate'].replace('data_files',' ')  for x in LogOutput]\n",
    "ydata = [y['executed_jobs'] for y in LogOutput]\n",
    "\n",
    "data = [go.Bar( x=xdata, y=ydata)]\n",
    "iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "mfrSubmit=  re.compile(' .*user=(?P<user>.*) group=(?P<group>.*) jobname=(?P<jobname>.*) queue=(?P<queue>.*) ctime=(?P<ctime>\\d+) qtime=(?P<qtime>\\d+) \\\n",
    "etime=(?P<etime>\\d+) start=(?P<start>\\d+) owner=(?P<owner>.*) exec_host=(?P<exec_host>.*)' )\n",
    "##my first regex\n",
    "\n",
    "mfrExec = re.compile('.*;(?P<jobEntryType>.);.*user=(?P<user>.*) group=(?P<group>.*) jobname=(?P<jobname>.*) queue=(?P<queue>.*) ctime=(?P<ctime>\\d+) qtime=(?P<qtime>\\d+) \\\n",
    "etime=(?P<etime>\\d+) start=(?P<start>\\d+) owner=(?P<owner>.*) exec_host=(?P<exec_host>.*)' )\n",
    "\n",
    "\n",
    "mfrExec2 = re.compile('.*;(?P<jobEntryType>.);.*user=(?P<user>.*) group=(?P<group>.*) jobname=(?P<jobname>.*) queue=(?P<queue>.*) ctime=(?P<ctime>\\d+) qtime=(?P<qtime>\\d+) etime=(?P<etime>\\d+) start=(?P<start>\\d+) owner=(?P<owner>.*) exec_host=(?P<exec_host>.*) Resource_List.neednodes=(?P<needNodes>\\d+):ppn=(?P<needppn>\\d+):(?P<needResourceName>.*) Resource_List.walltime=(?P<ndwalltime>.*) session=(?P<session>\\d+) total_execution_slots=(?P<totExecSlots>\\d+) unique_node_count=(?P<uniqueNodeCount>\\d+) end=(?P<endtime>\\d+) Exit_status=(?P<exitStatus>.) resources_used.cput=(?P<cpuTotal>.*) resources_used.mem=(?P<resourcesUsedMem>\\d+kb) resources_used.vmem=(?P<resourcesedUsedVMem>\\d+kb) resources_used.walltime=(?P<resourcesUsedWallTime>.*)')\n",
    "\n",
    "\n",
    "allExecutedJobs = []\n",
    "\n",
    "def analyze_data_file( fileName):\n",
    "    \"\"\"This will scan a log file from PBS/Torque and extract meaningful information about how many jobs were\n",
    "    run, how long they took, etc\"\"\"\n",
    "\n",
    "    executed_jobs = 0\n",
    "    wall_time = 0 ### This really should be parsed... and probably load the data into a database\n",
    "    \n",
    "    with open(fileName, 'rU') as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            m = mfrExec2.search(line)\n",
    "            if m:\n",
    "                if m.groupdict()['jobEntryType'] == \"E\":\n",
    "                    curJobInfo = m.groupdict()\n",
    "                    executed_jobs +=1\n",
    "                    allExecutedJobs.append(curJobInfo)\n",
    "\n",
    "                    \n",
    "                    \n",
    "    return (  {'LogDate': fileName, 'executed_jobs': executed_jobs})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Let's do some VERY basic analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('allExecJobs.pickle', 'w') as fp:\n",
    "    pickle.dump(allExecutedJobs,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_file = dataFiles[3]\n",
    "with  open(sample_file,'rU') as fp:\n",
    "    sampleData = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "mfr=  re.compile(' .*user=(?P<user>.*) group=(?P<group>.*) jobname=(?P<jobname>.*) queue=(?P<queue>.*) ctime=(?P<ctime>\\d+) qtime=(?P<qtime>\\d+) \\\n",
    "etime=(?P<etime>\\d+) start=(?P<start>\\d+) owner=(?P<owner>.*) exec_host=(?P<exec_host>.*) Resource_List.(?P<rsrc>.*) Resource_List.(?P<rsrc2>.*) \\\n",
    "Resource_List.(?P<rsrc3>.*)' )\n",
    "\n",
    "\n",
    "mfr=  re.compile(' .*user=(?P<user>.*) group=(?P<group>.*) jobname=(?P<jobname>.*) queue=(?P<queue>.*) ctime=(?P<ctime>\\d+) qtime=(?P<qtime>\\d+) \\\n",
    "etime=(?P<etime>\\d+) start=(?P<start>\\d+) owner=(?P<owner>.*) exec_host=(?P<exec_host>.*) Resource_List.(?P<rsrc>.*) Resource_List.(?P<rsrc2>.*) \\\n",
    "Resource_List.(?P<rsrc3>.*)' )\n",
    "\n",
    "\n",
    "###session=1417 total_execution_slots=2 unique_node_count=1 end=1458100531 Exit_status=0 resources_used.cput=00:00:17 resources_used.mem=2703476kb resources_used.vmem=4724852kb resources_used.walltime=00:01:08\n",
    "### I can parse the above separtely\n",
    "\n",
    "rsrcUsedList = re.compile('session=(?P<sessionID>.*) total_execution_slots=(?P<tExecSlots>\\d+) unique_node_count=(?P<uNodeCount>\\d+) \\\n",
    "end=(?P<end>\\d+) Exit_status=(?P<ExitStatus>.*) resources_used.cput=(?P<cput>.*) resources_used.mem=(?P<memUsed>\\d+kb) \\\n",
    "resources_used.vmem=(?P<vmem>\\d+kb) resources_used.walltime=(?P<walltime>.*)')\n",
    "\n",
    "sid = 5\n",
    "\n",
    "print sampleData[sid]\n",
    "# m= mfr.search(sampleData[sid])\n",
    "# if m:\n",
    "#     pprint( m.groupdict())\n",
    "\n",
    "m2 = rsrcUsedList.search(sampleData[sid])\n",
    "if m2:\n",
    "    pprint (m2.groupdict())\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in sampleData:\n",
    "    m2 = rsrcUsedList.search(r)\n",
    "    if m2:\n",
    "        pprint(m2.groupdict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
